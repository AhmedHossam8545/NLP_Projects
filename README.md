
# ğŸ¤– AI Projects Portfolio â€” Instant Software Solutions

This repository contains projects developed as part of my **AI & Data Science course** at **Instant Software Solutions**, where I explored hands-on implementations of Natural Language Processing, Machine Learning, and AI model deployment using real-world datasets and modern tools.

---

## ğŸ§  Project 1: Text Emotion Detection using Transformers

### ğŸ“˜ Overview
This project focuses on **Emotion Detection** in text using **Transformers** (DistilBERT model). It identifies emotions like **joy, anger, sadness, love**, and others from user text or datasets. The model is fine-tuned using Hugging Face Transformers and deployed interactively for real-time predictions.

### âš™ï¸ Features
âœ… Preprocesses and tokenizes text data using Hugging Face Tokenizer  
âœ… Fine-tunes a transformer model for multi-class emotion classification  
âœ… Supports evaluation with metrics like accuracy, F1-score, precision, and recall  
âœ… Easily deployable for real-world text emotion applications  

### ğŸ§© Tech Stack
| Component | Technology |
|------------|-------------|
| Programming Language | Python |
| Framework | Hugging Face Transformers |
| Libraries | TensorFlow, scikit-learn, Pandas, NumPy, Matplotlib |
| Platform | Google Colab / Jupyter Notebook |

### ğŸš€ How to Run
1ï¸âƒ£ Install dependencies  
```bash
pip install transformers tensorflow sklearn pandas numpy matplotlib
```

2ï¸âƒ£ Train the model  
```python
python train.py
```

3ï¸âƒ£ Test saved model  
```python
python test_model.py
```

### ğŸ§  Model Details
- Base model: **DistilBERT**
- Dataset: Custom-labeled emotion dataset (text + emotion labels)
- Classes: 4 detected emotions (Positive, Negative, Neutral, Mixed)

### ğŸ’¾ Saving and Reusing the Model
You can save and reload the fine-tuned transformer model folder directly (no need to retrain).  
Just upload and load it using:  
```python
model = TFAutoModelForSequenceClassification.from_pretrained("saved_model_folder")
```

### ğŸ’¡ Learning Outcomes
This project enhanced my understanding of:
- Transformer fine-tuning with labeled data  
- Emotion classification from text inputs  
- Model saving/loading and deployment  
- Evaluation metrics and performance tracking

---


## ğŸ§  Project 2: RAG Document Q&A App with FAISS + Gemini API
### ğŸ“˜ Overview

This advanced project integrates Retrieval-Augmented Generation (RAG) using FAISS for vector similarity search and Google Gemini API for powerful language reasoning.
Users can upload documents and ask complex questions that the AI answers using retrieved context â€” combining local knowledge + generative intelligence.

### âš™ï¸ Features

âœ… Document upload and text extraction (pdfplumber)
âœ… Chunk splitting and embedding with sentence-transformers
âœ… Semantic retrieval via FAISS index
âœ… Context-aware answers from Gemini API
âœ… Streamlit web app interface
âœ… Automatic safety-filter handling and retry for Gemini

### ğŸ§© Tech Stack
Component	Technology
Language	Python
Vector Search	FAISS
Embeddings	Sentence-Transformers (all-MiniLM-L6-v2)
LLM API	Google Gemini API
Interface	Streamlit
Libraries	pdfplumber, faiss, numpy, google-generativeai
### ğŸš€ How to Run

1ï¸âƒ£ Install dependencies

pip install streamlit google-generativeai sentence-transformers faiss-cpu pdfplumber


2ï¸âƒ£ Add your Gemini API key in the code or Streamlit secrets
3ï¸âƒ£ Run the app

streamlit run app.py

### ğŸ“‚ Structure
ğŸ“ RAG_Gemini_FAISS_App/
â”‚
â”œâ”€â”€ app.py           # Main Streamlit App
â”œâ”€â”€ faiss_index.bin   # Saved FAISS Index
â”œâ”€â”€ text_chunks.pkl   # Chunk Data
â””â”€â”€ requirements.txt

### ğŸ’¡ Learning Outcomes

Understanding RAG pipelines and document retrieval

Building semantic search with FAISS

Integrating Gemini API for intelligent answer generation

Designing robust Streamlit apps with LLM connectivity


---
## ğŸ§  Project 3: AI Text Summarizer & Question Answering App

### ğŸ“˜ Overview
The AI Text Summarizer & Question Answering App is an interactive NLP tool built using **Streamlit** and **Hugging Face Transformers** that allows users to:
- Upload PDF or TXT files, or paste text manually  
- Automatically summarize long documents using smart chunking  
- Ask questions about the uploaded content using an integrated Question Answering model  

It demonstrates practical applications of NLP in document understanding and automation.

### âš™ï¸ Features
âœ… Summarizes large or complex text (automatic chunking)  
âœ… Supports `.pdf`, `.txt`, and direct text input  
âœ… Provides interactive Q&A from summarized text  
âœ… Clean Streamlit UI for real-time use  
âœ… Uses state-of-the-art NLP models from Hugging Face  

### ğŸ§© Tech Stack
| Component | Technology |
|------------|-------------|
| Programming Language | Python |
| Web Framework | Streamlit |
| NLP Models | Hugging Face Transformers (BART, DistilBERT) |
| Libraries | pdfplumber, torch, transformers |
| Platform | Google Colab / Local Deployment |

### ğŸš€ How to Run
1ï¸âƒ£ Install dependencies  
```bash
pip install streamlit transformers torch pdfplumber
```

2ï¸âƒ£ Run the app  
```bash
streamlit run app.py
```

3ï¸âƒ£ Open in browser at `http://localhost:8501/`

### ğŸ“‚ Project Structure
```
ğŸ“ AI_Text_Summarizer_QA/
â”‚
â”œâ”€â”€ app.py                 # Main Streamlit app
â”œâ”€â”€ requirements.txt       # Required packages
â””â”€â”€ sample_text.txt        # Example test text
```

### ğŸ§  Models Used
- **Summarization:** `facebook/bart-large-cnn`  
- **Question Answering:** `deepset/roberta-base-squad2`

### ğŸ’¡ Learning Outcomes
This project helped me strengthen my understanding of:
- Transformer-based NLP models (BART, DistilBERT, RoBERTa)  
- Handling large documents with chunking techniques  
- Deploying interactive AI applications with Streamlit  
- Combining summarization and Q&A tasks in one workflow  

---

### ğŸŒŸ Acknowledgment
Developed as part of my training projects with **Instant Software Solutions** â€” a leading AI and Data Science training center that focuses on hands-on learning and real-world applications.
