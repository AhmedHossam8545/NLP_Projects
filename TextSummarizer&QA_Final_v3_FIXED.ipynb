{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "iD2vLYZShGHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers streamlit pyngrok pdfplumber python-docx -q\n"
      ],
      "metadata": {
        "id": "6QRtvPrwgTAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build Models and Needed Functions"
      ],
      "metadata": {
        "id": "fbqRRqmohJ6Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563,
          "referenced_widgets": [
            "4fe7e0de9de44e7b83d35d6c2fd58ea3",
            "9631253996e646598d59cdd858a0daa8",
            "8882f676a37342379460adb4112097da",
            "e9df669b7717443bb67c4c535d4194e3",
            "66fe7c3f00b24093a9739a5039bc868c",
            "67d3cecd1dd84b558b377beed37ddcc1",
            "e7d3362b6eb94d09883a85c5d6271ba4",
            "38770c29ff394101b6b39669ecec50e5",
            "fc4d0641733742f29670172a75fcdecf",
            "9116caf9a7594468b737615853741c62",
            "fad1e26c7f1646c6962f3f7c3714b179",
            "a7a16b6cf4bc4890b16f8687a3774168",
            "94bb3ba6f01e43f49946cbbedb3ca6f1",
            "986f6461f969446a995bc6f1b3b06812",
            "3121e43b83a94782ad857d571704b72f",
            "36c2380820ed40aa9cfd70ccb38f6072",
            "9dc43e869a5d4234b225e24ed5dcc1b1",
            "fd48952045144776b1e1f78ec7524d76",
            "350f6b89c8ed42b9b92b1dd354faf9c3",
            "388d71024a51444eb428f606b4a5cd61",
            "29f7740bab0047b3bfa28a8dfcc110c9",
            "11e24c176bfe4c2cbffb813bb8471904",
            "4c62e3f26d9a4c698d19164a7757a65c",
            "abeb4d73e5584c5990845aebf89aebaf",
            "e84fd7591dfe4ea9a858a9054c87a6aa",
            "0fc1914b8d424cb1b882e739fcca5b1c",
            "0c682d8af50647c6bf95872ade5022aa",
            "112f7eb88f6e4500854766179e44cb27",
            "c723f7f141e7463d9bf94be993230fa5",
            "8c7f476cd4a14bd185b0c821af0b7712",
            "a100d989efb14fdc8748e7391d3af726",
            "db53b165d1724dde8c0e95425113da80",
            "8edbaacc34d84f2c9c3e36042ce62a54",
            "de5b1ba30c6f4c0e82192241cfa61cb6",
            "d9308336f33f44159d58768f18e3f8fe",
            "c68abec8a3b14315bea7903d902c094d",
            "e5d99325cf914ec4ba921af03dc39b11",
            "4162c8897bc241ae9a51884f60763179",
            "a38ce772acf54dffb61306ef526634fa",
            "79cd20b8fbff45cb9f8f51e73bcdd4b5",
            "4b3b631c04864a42bb0a648da363ab2b",
            "86b8c7a58d294136a56d391df7da2ade",
            "d34281e21bd9403bb4de974a3b056d73",
            "9452315f621349baa349c37fcce1858e",
            "15aecd8d3ba44a52a2b21aa898885786",
            "4b0acc577a7346458984212db145c8c3",
            "4fa3721a291f4bf38c834c28aed05312",
            "356d062f4c144cc58c9a322ea1dab250",
            "1883a17ea28e4172bbb4ce39a53cae35",
            "14c75e9e5d094c7bad872ad85dd4e661",
            "2ef0315b53fc4340867b48ae3bdb62b6",
            "35e27986a7194b34a500df1d35376053",
            "3942ed0fb83c401888c9424d0d096b45",
            "035da59e9dbf4960b25110d8886e77e7",
            "eb49e16155ef4a2ab5100fee39854cdd",
            "5422e6413d274f8d919ebc5bae834a0f",
            "551d66ade42549dfb833ec14b6286801",
            "689d81dd8fac4c69a110e0ead24a3d35",
            "f8d92f7216294b0fb2d68aadda48266a",
            "71eef6e458004e3487dac997171b7ebd",
            "216bcbce485f4bc18214b6cbb689e8d8",
            "d4a6007069b540eab2fe2a3ea4d135c3",
            "9f0e3c3bbb834668a7905ea45ee2b063",
            "064b9564eac340d5a73943427f9c736e",
            "b6756bb18b8b40e788b3f58b6390d5e7",
            "e435e1eb794640389703025485b78d8f",
            "09545af271fb49009f268cfbda2fa1b5",
            "85f2d0c600c442129a723926f1945899",
            "df665b8fa4494e9f9782fcbb8fc0cab5",
            "3430d658391c41019bd3d6ca7888d4f9",
            "8f5c2383ebd84d6da4754bc13eb98a1f",
            "16f915d24d124bb4ac5baa741eb83581",
            "80dd2677945f44a6b33ea137738ed42c",
            "d82cf1e366fc47a5897e58678751a189",
            "d077160d939442ac8497ba3923a9900b",
            "2173ce35216b4071914de5c0f07e49f7",
            "a67bf0bc019c4867920ccc446bda6c38",
            "1e75aef17cf148d8a5cb13036196052e",
            "d933b1839334474cb0f496bdc12a02d3",
            "e1f2af354894445da218a0a8cf80f97c",
            "e4d500bf18c1492aadd35b877df8fd5a",
            "3bcd4ffdcdbd4e10ae10210fe1ec19c9",
            "ef8a92c2fc9c424e976da18cb1a9dced",
            "b36f25d941d94b6b8a3e05ec35a211a6",
            "8e761472d43a476080fed61c62bc65af",
            "8d59081fb0c6482f9dddbca7d750f515",
            "bb5c2dde6d204f5b92728b94b0c9e017",
            "fefe07022f544d1bb15c88e598ec8cc3",
            "5ac9357db7c64fe6beb9f9c195cc6e43",
            "02af9da7e0044bf497808d3218a67812",
            "d7687b102ed3471ba26d1be81d8b504f",
            "79ad04c2916744e395bc65895c35e819",
            "1595017edc1d48cc8b385efc62ce0c5a",
            "ad2bb1ed89e744479f8fb000a82ce4d1",
            "295553c32c384d60bddb41ffd6d08051",
            "0284ed1b1b5f4bb7a86b41b68cb46451",
            "018f96ed801d4855b102869c1505638c",
            "b9783b30a0b040b5a5400739df8d4dd5",
            "3f20f8ec76194364a8e77bf3121e914d",
            "c44402c2f9284e0aae92699f68e12618",
            "91b259048ca04b8b867dca9aa48202d5",
            "bde6477555b94f4689b4c71a90fde093",
            "1ff43585b3e0421bac5aa18bb73dbd8d",
            "3409a7159cba401dac4222e1f0a3953c",
            "9cb0b54af599448ba2558bad90082f03",
            "ef8a85ab7c2a415b8c594f652966679a",
            "c8ebc034b55c490eb85de6e3846a57fe",
            "9854afcd182d425c8e20b04f746084a4",
            "be92b209395848e6b9fddff447bcd2f2",
            "d72967be896e4a3c9a9546372b8459ae",
            "7c012b62b612447293e0fd147f146372",
            "47c6c145182e435eb5dace12c6f86e41",
            "9d9ee39096374e61b7afcdeb7750c7aa",
            "a1f9f1b611ef4965a067422ca255dbb8",
            "bf19c2a9de3949619d68415f7e4096c1",
            "7124462611444b93a5e3cad5cc6e1dd7",
            "5bcfd0da3cbc4dd4b7f1bf1a4ee5a8fe",
            "f594c880bf4d40feb474c54e2c37c363",
            "a5dde1cb9c8d4b639b63e21879280b91",
            "941a4c5d48de44e3885c474cf5febf85",
            "0c6e405765114466af9471e4705d988b"
          ]
        },
        "id": "GdevfWr-eA2s",
        "outputId": "a83186f0-97c0-4177-dc6a-662026b22b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fe7e0de9de44e7b83d35d6c2fd58ea3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7a16b6cf4bc4890b16f8687a3774168"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c62e3f26d9a4c698d19164a7757a65c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de5b1ba30c6f4c0e82192241cfa61cb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15aecd8d3ba44a52a2b21aa898885786"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5422e6413d274f8d919ebc5bae834a0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09545af271fb49009f268cfbda2fa1b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e75aef17cf148d8a5cb13036196052e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ac9357db7c64fe6beb9f9c195cc6e43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c44402c2f9284e0aae92699f68e12618"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c012b62b612447293e0fd147f146372"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "def summarize_text(text, max_len=130, min_len=30):\n",
        "    \"\"\"Generate summary from input text.\"\"\"\n",
        "    summary = summarizer(text, max_length=max_len, min_length=min_len, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "def answer_question(context, question):\n",
        "    \"\"\"Answer a question based on the context text.\"\"\"\n",
        "    result = qa_pipeline(question=question, context=context)\n",
        "    return result['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deployment"
      ],
      "metadata": {
        "id": "_Df3rvgThPex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from transformers import pipeline\n",
        "import pdfplumber\n",
        "import torch\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", device=device)\n",
        "\n",
        "def read_pdf(file):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(file) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "def read_txt(file):\n",
        "    return file.read().decode(\"utf-8\")\n",
        "\n",
        "def chunk_text(text, max_chunk_size=1000):\n",
        "    sentences = text.split(\". \")\n",
        "    chunks, current_chunk = [], \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) + 1 <= max_chunk_size:\n",
        "            current_chunk += sentence + \". \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \". \"\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "st.title(\"\ud83d\udcd8 AI Text Summarizer & Q&A App\")\n",
        "st.markdown(\"Upload a PDF or TXT file, or paste text directly, then summarize or ask questions about it!\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a file (.pdf or .txt)\", type=[\"pdf\", \"txt\"])\n",
        "text_input = st.text_area(\"Or paste your text here:\", height=200)\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    if uploaded_file.name.endswith(\".pdf\"):\n",
        "        text_input = read_pdf(uploaded_file)\n",
        "    elif uploaded_file.name.endswith(\".txt\"):\n",
        "        text_input = read_txt(uploaded_file)\n",
        "\n",
        "if st.button(\"Summarize Text\"):\n",
        "    if text_input:\n",
        "        chunks = chunk_text(text_input, max_chunk_size=1000)\n",
        "        st.write(f\"\ud83d\udd39 Document split into {len(chunks)} chunks.\")\n",
        "\n",
        "        summaries = []\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            st.write(f\"Summarizing chunk {i+1}/{len(chunks)}...\")\n",
        "            summary = summarizer(chunk, max_length=200, min_length=30, do_sample=False)[0]['summary_text']\n",
        "            summaries.append(summary)\n",
        "\n",
        "        final_summary = \" \".join(summaries)\n",
        "        st.subheader(\"\ud83d\udcdd Summary\")\n",
        "        st.write(final_summary)\n",
        "    else:\n",
        "        st.warning(\"Please upload or enter text first!\")\n",
        "\n",
        "st.subheader(\"\ud83d\udcac Ask a Question about the Text\")\n",
        "question = st.text_input(\"Enter your question here:\")\n",
        "\n",
        "if st.button(\"Get Answer\"):\n",
        "    if text_input and question:\n",
        "        try:\n",
        "            answer = qa_pipeline(question=question, context=text_input)['answer']\n",
        "            st.success(f\"**Answer:** {answer}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error while answering: {e}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter both a question and text.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVo99xAdkLBd",
        "outputId": "1359d5d8-a155-426c-ae98-4c55eb9d26b8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "!ngrok authtoken 33fLuUGd0W0b3hxMtmN0QgJvLsi_As5QsijWrWBvHDeBA3oC\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaMMldrlece4",
        "outputId": "67ec6c2b-b00f-43b2-f445-11d47ecd9512"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "get_ipython().system_raw('streamlit run app.py --server.port 8501 &')\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EOHRrxged3n",
        "outputId": "17bcf998-3e2c-4d16-848a-29dc4798e2f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://retta-acidy-nongenerically.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}